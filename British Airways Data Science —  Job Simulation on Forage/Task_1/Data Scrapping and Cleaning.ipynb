{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e8390d7",
   "metadata": {},
   "source": [
    "# Web Scraping and Analysis of British Airways Reviews\n",
    "\n",
    "This script automates the process of scraping customer reviews from British Airways' review pages. Utilizing libraries such as `requests` and `BeautifulSoup` for web scraping, it collects reviews across 50 pages, each containing up to 100 reviews. \n",
    "\n",
    "Data extracted includes author names, review content, ratings, and publication dates. Additional review statistics are also gathered. The reviews are stored in a pandas DataFrame, cleaned for missing values, and finally saved to a CSV file. Visual and textual analysis, such as generating word clouds and sentiment analysis, can be performed on the cleaned dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4e81ac",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63f6a9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import time \n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa1901a",
   "metadata": {},
   "source": [
    "### Setting Up Scraping Parameters.\n",
    "\n",
    "This section defines the key parameters and initializes storage for web scraping.\n",
    "\n",
    "- base_url: Sets the target URL for British Airways reviews on the Airline Quality website.\n",
    "- pages_to_scrape: Determines the number of pages to scrape, set to 50.\n",
    "- page_size: Specifies the number of reviews per page, set to 100.\n",
    "- all_reviews: Initializes an empty list to store reviews collected across pages. This list will be filled with review data as each page is processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9f82d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the webiste to scrape \n",
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages_to_scrape = 50\n",
    "page_size = 100\n",
    "\n",
    "# Initialize the list to store all reviews across pages\n",
    "all_reviews = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28a4e9a",
   "metadata": {},
   "source": [
    "### Scrapping British Airways Reviews\n",
    "\n",
    "This section demonstrates the process of iterating through multiple pages of British Airways reviews, extracting key information, and storing it for analysis.\n",
    "\n",
    "### Steps for Scraping British Airways Reviews\n",
    "1. Iterate Pages: Loop through specified pages, printing the current page number.\n",
    "2. Construct URL: Form the URL for each page.\n",
    "3. Fetch and Parse: Request and parse HTML with BeautifulSoup.\n",
    "4. Extract Data: Extract review details and statistics.\n",
    "5. Store Data: Append data to lists.\n",
    "6. Delay: Introduce a one-second delay.\n",
    "7. Print Progress: Display the number of reviews collected per page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1bfeace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 reviews on page 1\n",
      "Scraping page 2\n",
      "   ---> 100 reviews on page 2\n",
      "Scraping page 3\n",
      "   ---> 100 reviews on page 3\n",
      "Scraping page 4\n",
      "   ---> 100 reviews on page 4\n",
      "Scraping page 5\n",
      "   ---> 100 reviews on page 5\n",
      "Scraping page 6\n",
      "   ---> 100 reviews on page 6\n",
      "Scraping page 7\n",
      "   ---> 100 reviews on page 7\n",
      "Scraping page 8\n",
      "   ---> 100 reviews on page 8\n",
      "Scraping page 9\n",
      "   ---> 100 reviews on page 9\n",
      "Scraping page 10\n",
      "   ---> 100 reviews on page 10\n",
      "Scraping page 11\n",
      "   ---> 100 reviews on page 11\n",
      "Scraping page 12\n",
      "   ---> 100 reviews on page 12\n",
      "Scraping page 13\n",
      "   ---> 100 reviews on page 13\n",
      "Scraping page 14\n",
      "   ---> 100 reviews on page 14\n",
      "Scraping page 15\n",
      "   ---> 100 reviews on page 15\n",
      "Scraping page 16\n",
      "   ---> 100 reviews on page 16\n",
      "Scraping page 17\n",
      "   ---> 100 reviews on page 17\n",
      "Scraping page 18\n",
      "   ---> 100 reviews on page 18\n",
      "Scraping page 19\n",
      "   ---> 100 reviews on page 19\n",
      "Scraping page 20\n",
      "   ---> 100 reviews on page 20\n",
      "Scraping page 21\n",
      "   ---> 100 reviews on page 21\n",
      "Scraping page 22\n",
      "   ---> 100 reviews on page 22\n",
      "Scraping page 23\n",
      "   ---> 100 reviews on page 23\n",
      "Scraping page 24\n",
      "   ---> 100 reviews on page 24\n",
      "Scraping page 25\n",
      "   ---> 100 reviews on page 25\n",
      "Scraping page 26\n",
      "   ---> 100 reviews on page 26\n",
      "Scraping page 27\n",
      "   ---> 100 reviews on page 27\n",
      "Scraping page 28\n",
      "   ---> 100 reviews on page 28\n",
      "Scraping page 29\n",
      "   ---> 100 reviews on page 29\n",
      "Scraping page 30\n",
      "   ---> 100 reviews on page 30\n",
      "Scraping page 31\n",
      "   ---> 100 reviews on page 31\n",
      "Scraping page 32\n",
      "   ---> 100 reviews on page 32\n",
      "Scraping page 33\n",
      "   ---> 100 reviews on page 33\n",
      "Scraping page 34\n",
      "   ---> 100 reviews on page 34\n",
      "Scraping page 35\n",
      "   ---> 100 reviews on page 35\n",
      "Scraping page 36\n",
      "   ---> 100 reviews on page 36\n",
      "Scraping page 37\n",
      "   ---> 100 reviews on page 37\n",
      "Scraping page 38\n",
      "   ---> 100 reviews on page 38\n",
      "Scraping page 39\n",
      "   ---> 9 reviews on page 39\n",
      "Scraping page 40\n",
      "   ---> 0 reviews on page 40\n",
      "Scraping page 41\n",
      "   ---> 0 reviews on page 41\n",
      "Scraping page 42\n",
      "   ---> 0 reviews on page 42\n",
      "Scraping page 43\n",
      "   ---> 0 reviews on page 43\n",
      "Scraping page 44\n",
      "   ---> 0 reviews on page 44\n",
      "Scraping page 45\n",
      "   ---> 0 reviews on page 45\n",
      "Scraping page 46\n",
      "   ---> 0 reviews on page 46\n",
      "Scraping page 47\n",
      "   ---> 0 reviews on page 47\n",
      "Scraping page 48\n",
      "   ---> 0 reviews on page 48\n",
      "Scraping page 49\n",
      "   ---> 0 reviews on page 49\n",
      "Scraping page 50\n",
      "   ---> 0 reviews on page 50\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, pages_to_scrape + 1):\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "    # Extract the relevant information from the HTML code\n",
    "    page_reviews = []\n",
    "    for article in parsed_content.find_all('article', class_='comp_media-review-rated'):\n",
    "        \n",
    "        # Extracting data directly from the article\n",
    "        rating_value_tag = article.find('span', itemprop='ratingValue')\n",
    "        rating_value = rating_value_tag.get_text() if rating_value_tag else None\n",
    "\n",
    "        rating_max_tag = article.find('span', itemprop='bestRating')\n",
    "        rating_max = rating_max_tag.get_text() if rating_max_tag else None\n",
    "\n",
    "        review_title_tag = article.find('h2', class_='text_header')\n",
    "        review_title = review_title_tag.get_text(strip=True) if review_title_tag else None\n",
    "\n",
    "        author_name_tag = article.find('span', itemprop='name')\n",
    "        author_name = author_name_tag.get_text(strip=True) if author_name_tag else None\n",
    "\n",
    "        date_published_tag = article.find('time', itemprop='datePublished')\n",
    "        date_published = date_published_tag['datetime'] if date_published_tag else None\n",
    "\n",
    "        review_body_tag = article.find('div', itemprop='reviewBody')\n",
    "        review_body = review_body_tag.get_text(strip=True) if review_body_tag else None\n",
    "\n",
    "        # Extracting additional information from the review-stats table\n",
    "        review_stats = article.find('table', class_='review-ratings')\n",
    "        data = {}\n",
    "        for item in review_stats.find_all('tr'):\n",
    "            header = item.find('td', class_='review-rating-header')\n",
    "            value = item.find('td', class_='review-value')\n",
    "            if header and value:\n",
    "                data[header.text.strip()] = value.text.strip()\n",
    "\n",
    "        page_reviews.append({\n",
    "            'AuthorName': author_name,\n",
    "            'ReviewBody': review_body,\n",
    "            'RatingValue': rating_value,\n",
    "            'RatingMax': rating_max,\n",
    "            'ReviewTitle': review_title,\n",
    "            'DatePublished': date_published,\n",
    "            **data  # Include additional information from the review-stats table\n",
    "        })\n",
    "\n",
    "    all_reviews.extend(page_reviews)  # Extend the list with reviews from the current page\n",
    "\n",
    "    # Add a delay between requests to avoid overwhelming the website with requests\n",
    "    time.sleep(1)\n",
    "\n",
    "    print(f\"   ---> {len(page_reviews)} reviews on page {i}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275e2689",
   "metadata": {},
   "source": [
    "### Storing Scraped Data\n",
    "\n",
    "The following code stores the collected reviews into a pandas DataFrame.and displays the first five rows of the dataframe. This creates a structured tabular format for easier data manipulation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed9c52ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AuthorName</th>\n",
       "      <th>ReviewBody</th>\n",
       "      <th>RatingValue</th>\n",
       "      <th>RatingMax</th>\n",
       "      <th>ReviewTitle</th>\n",
       "      <th>DatePublished</th>\n",
       "      <th>Aircraft</th>\n",
       "      <th>Type Of Traveller</th>\n",
       "      <th>Seat Type</th>\n",
       "      <th>Route</th>\n",
       "      <th>Date Flown</th>\n",
       "      <th>Recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jonathan Rodden</td>\n",
       "      <td>✅Trip Verified|  Flew British Airways on BA 43...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>\"flight itself was quite good\"</td>\n",
       "      <td>2024-06-10</td>\n",
       "      <td>A320</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Business Class</td>\n",
       "      <td>London to Amsterdam</td>\n",
       "      <td>May 2024</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Hammad</td>\n",
       "      <td>✅Trip Verified|  BA cancelled the flight from ...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>\"You expect better from BA\"</td>\n",
       "      <td>2024-06-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Couple Leisure</td>\n",
       "      <td>Premium Economy</td>\n",
       "      <td>Tokyo to Manchester via London</td>\n",
       "      <td>May 2024</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D Baker</td>\n",
       "      <td>✅Trip Verified| I strongly advise everyone to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>“never fly British Airways\"</td>\n",
       "      <td>2024-06-06</td>\n",
       "      <td>Boeing 747</td>\n",
       "      <td>Business</td>\n",
       "      <td>Business Class</td>\n",
       "      <td>Heathrow to San Francisco</td>\n",
       "      <td>June 2024</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Val Rose</td>\n",
       "      <td>✅Trip Verified| My partner and I were on the B...</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>“we will rethink BA moving forward”</td>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Couple Leisure</td>\n",
       "      <td>Business Class</td>\n",
       "      <td>Tampa to Gatwick</td>\n",
       "      <td>May 2024</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jason George</td>\n",
       "      <td>Not Verified|  We had a Premium Economy return...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>“extremely poor customer service”</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Premium Economy</td>\n",
       "      <td>Los Angeles to London</td>\n",
       "      <td>January 2024</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AuthorName                                         ReviewBody  \\\n",
       "0  Jonathan Rodden  ✅Trip Verified|  Flew British Airways on BA 43...   \n",
       "1         A Hammad  ✅Trip Verified|  BA cancelled the flight from ...   \n",
       "2          D Baker  ✅Trip Verified| I strongly advise everyone to ...   \n",
       "3         Val Rose  ✅Trip Verified| My partner and I were on the B...   \n",
       "4     Jason George  Not Verified|  We had a Premium Economy return...   \n",
       "\n",
       "  RatingValue RatingMax                          ReviewTitle DatePublished  \\\n",
       "0           9        10       \"flight itself was quite good\"    2024-06-10   \n",
       "1           1        10          \"You expect better from BA\"    2024-06-09   \n",
       "2           1        10          “never fly British Airways\"    2024-06-06   \n",
       "3           5        10  “we will rethink BA moving forward”    2024-06-03   \n",
       "4           1        10    “extremely poor customer service”    2024-06-01   \n",
       "\n",
       "     Aircraft Type Of Traveller        Seat Type  \\\n",
       "0        A320      Solo Leisure   Business Class   \n",
       "1         NaN    Couple Leisure  Premium Economy   \n",
       "2  Boeing 747          Business   Business Class   \n",
       "3         NaN    Couple Leisure   Business Class   \n",
       "4         NaN    Family Leisure  Premium Economy   \n",
       "\n",
       "                            Route    Date Flown Recommended  \n",
       "0             London to Amsterdam      May 2024         yes  \n",
       "1  Tokyo to Manchester via London      May 2024          no  \n",
       "2       Heathrow to San Francisco     June 2024          no  \n",
       "3                Tampa to Gatwick      May 2024          no  \n",
       "4           Los Angeles to London  January 2024          no  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store all reviews in a pandas dataframe\n",
    "df = pd.DataFrame(all_reviews)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a2bc69",
   "metadata": {},
   "source": [
    "### Saving the Scraped Data as a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ffd1ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv file \n",
    "df.to_csv(\"data/BA_scrapped_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0239f33d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
